import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
import math
from sklearn.metrics import r2_score
import random
from sklearn import ensemble
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor
import matplotlib.pyplot as plt

def load_data(filename):
    train_feat = []
    train_id = []
    data = []
    with open(filename, 'r') as f:
        file = f.readlines()
        for h in file:
            line = h.strip().split(',')
#
            x_l = [math.log(float(line[0]), 10)]
            # print(len(line[1]))
            #对目标值取log对数
            for a in line[1]: #将序列编码
                if a == 'A':
                    x_l.append(6)
                if a == 'G':
                    x_l.append(1)
                if a == 'T':
                    x_l.append(2)
                if a == 'C':
                    x_l.append(3)
                if a == 'B':
                    x_l.append(0)
            x_l = np.array(x_l)
            data.append(x_l)
    random.shuffle(data)
    for t in data:
        train_feat.append(t[1:])
        train_id.append(t[0])
        #print(train_id)
    train_feat = np.array(train_feat)
    train_id = np.array(train_id)
    return train_feat, train_id
#
for i in range(1):
    train_feat, train_id = load_data('train5.csv')
    normalized_test_data = (train_feat - np.mean(train_feat) / np.std(train_feat)) #标准化数据
    #X_train, X_test, y_train, y_test = train_test_split(normalized_test_data, train_id, test_size=0.1, random_state=0) #分割数据集
    X_train, X_test, y_train, y_test = train_test_split(train_feat, train_id, test_size=0.2, random_state=0) #分割数据集
    #regr = DecisionTreeRegressor()
    #regr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=100),n_estimators=10000)
    regr = AdaBoostRegressor(DecisionTreeRegressor())
    #regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='exponential',n_estimators=50, random_state=0)

    regr.fit(train_feat, train_id)
    #pred = regr.predict(train_feat)
    #score = r2_score(train_id, pred) #R2相关系数

    #regr.fit(X_train, y_train)
    pred = regr.predict(X_test)
    y_test=pow(10,y_test)
    pred=pow(10,pred)
    score = r2_score(y_test, pred)  # R2相关系数
#
    print(score)
    #print(pow(10, pred))
    #print(pow(10,train_id))
    #print(pow(10,pred) - pow(10,y_test))

    #plt.figure()
    #plt.scatter(y_test, pred, s=5,c="k", label="ada")
    #plt.plot(X, y_1, c="g", label="n_estimators=1", linewidth=2)
    #plt.plot(y_test, pred, c="r", label="test", linewidth=2)
    #plt.xlabel("test")
    #plt.ylabel("pred")
    #plt.legend()
    #plt.show()'''
